{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  pd.read_csv(\"bill_authentication.csv\")\n",
    "#Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization,\n",
    "#an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. \n",
    "#Due to the object lens and distance to the investigated object gray-scale pictures\n",
    "#with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.807300</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.458600</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.924200</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.011200</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.36840</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.960600</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.59120</td>\n",
       "      <td>3.01290</td>\n",
       "      <td>0.728880</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.09220</td>\n",
       "      <td>-6.81000</td>\n",
       "      <td>8.463600</td>\n",
       "      <td>-0.602160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.20320</td>\n",
       "      <td>5.75880</td>\n",
       "      <td>-0.753450</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.53560</td>\n",
       "      <td>9.17720</td>\n",
       "      <td>-2.271800</td>\n",
       "      <td>-0.735350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.22470</td>\n",
       "      <td>8.77790</td>\n",
       "      <td>-2.213500</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.98990</td>\n",
       "      <td>-2.70660</td>\n",
       "      <td>2.394600</td>\n",
       "      <td>0.862910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.89930</td>\n",
       "      <td>7.66250</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>-3.110800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.57680</td>\n",
       "      <td>10.84300</td>\n",
       "      <td>2.546200</td>\n",
       "      <td>-2.936200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.40400</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.991500</td>\n",
       "      <td>-0.572420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.67650</td>\n",
       "      <td>-3.38950</td>\n",
       "      <td>3.489600</td>\n",
       "      <td>1.477100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.67190</td>\n",
       "      <td>3.06460</td>\n",
       "      <td>0.371580</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.80355</td>\n",
       "      <td>2.84730</td>\n",
       "      <td>4.343900</td>\n",
       "      <td>0.601700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.44790</td>\n",
       "      <td>-4.87940</td>\n",
       "      <td>8.342800</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.24230</td>\n",
       "      <td>11.02720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.101300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.78670</td>\n",
       "      <td>7.89020</td>\n",
       "      <td>-2.619600</td>\n",
       "      <td>-0.487080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.32920</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.93620</td>\n",
       "      <td>10.16220</td>\n",
       "      <td>-3.823500</td>\n",
       "      <td>-4.017200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.93584</td>\n",
       "      <td>8.88550</td>\n",
       "      <td>-1.683100</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.43380</td>\n",
       "      <td>9.88700</td>\n",
       "      <td>-4.679500</td>\n",
       "      <td>-3.748300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.70570</td>\n",
       "      <td>-5.49810</td>\n",
       "      <td>8.336800</td>\n",
       "      <td>-2.871500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.14320</td>\n",
       "      <td>-3.74130</td>\n",
       "      <td>5.577700</td>\n",
       "      <td>-0.635780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.38214</td>\n",
       "      <td>8.39090</td>\n",
       "      <td>2.162400</td>\n",
       "      <td>-3.740500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.56330</td>\n",
       "      <td>9.81870</td>\n",
       "      <td>-4.411300</td>\n",
       "      <td>-3.225800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.89060</td>\n",
       "      <td>-3.35840</td>\n",
       "      <td>3.420200</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-2.32990</td>\n",
       "      <td>-9.95320</td>\n",
       "      <td>8.475600</td>\n",
       "      <td>-1.873300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.00312</td>\n",
       "      <td>-4.00610</td>\n",
       "      <td>1.795600</td>\n",
       "      <td>0.917220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>1.35180</td>\n",
       "      <td>1.05950</td>\n",
       "      <td>-2.343700</td>\n",
       "      <td>0.399980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1.23090</td>\n",
       "      <td>3.89230</td>\n",
       "      <td>-4.827700</td>\n",
       "      <td>-4.006900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-5.03010</td>\n",
       "      <td>7.50320</td>\n",
       "      <td>-0.133960</td>\n",
       "      <td>-7.503400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>-3.07990</td>\n",
       "      <td>0.60836</td>\n",
       "      <td>2.703900</td>\n",
       "      <td>-0.237510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>-2.29870</td>\n",
       "      <td>-5.22700</td>\n",
       "      <td>5.630000</td>\n",
       "      <td>0.917220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-1.23900</td>\n",
       "      <td>-6.54100</td>\n",
       "      <td>4.815100</td>\n",
       "      <td>-0.033204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.75896</td>\n",
       "      <td>0.29176</td>\n",
       "      <td>-1.650600</td>\n",
       "      <td>0.838340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.67990</td>\n",
       "      <td>4.20680</td>\n",
       "      <td>-4.539800</td>\n",
       "      <td>-2.393100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.63655</td>\n",
       "      <td>5.20220</td>\n",
       "      <td>-5.215900</td>\n",
       "      <td>-6.121100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-6.05980</td>\n",
       "      <td>9.29520</td>\n",
       "      <td>-0.436420</td>\n",
       "      <td>-6.369400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-3.51800</td>\n",
       "      <td>2.87630</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>-1.208600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-2.03360</td>\n",
       "      <td>-1.40920</td>\n",
       "      <td>1.158200</td>\n",
       "      <td>0.365070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>-0.69745</td>\n",
       "      <td>-1.76720</td>\n",
       "      <td>-0.344740</td>\n",
       "      <td>-0.123720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.75108</td>\n",
       "      <td>1.91610</td>\n",
       "      <td>-3.109800</td>\n",
       "      <td>-0.205180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.84546</td>\n",
       "      <td>3.48260</td>\n",
       "      <td>-3.630700</td>\n",
       "      <td>-1.396100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.55648</td>\n",
       "      <td>3.21360</td>\n",
       "      <td>-3.308500</td>\n",
       "      <td>-2.796500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>-3.68170</td>\n",
       "      <td>3.22390</td>\n",
       "      <td>-0.693470</td>\n",
       "      <td>-3.400400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-6.75260</td>\n",
       "      <td>8.81720</td>\n",
       "      <td>-0.061983</td>\n",
       "      <td>-3.725000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-4.57700</td>\n",
       "      <td>3.45150</td>\n",
       "      <td>0.667190</td>\n",
       "      <td>-0.947420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-2.98830</td>\n",
       "      <td>0.31245</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.068951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-1.47810</td>\n",
       "      <td>0.14277</td>\n",
       "      <td>-1.162200</td>\n",
       "      <td>-0.485790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-0.46651</td>\n",
       "      <td>2.33830</td>\n",
       "      <td>-2.981200</td>\n",
       "      <td>-1.043100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.87340</td>\n",
       "      <td>1.65330</td>\n",
       "      <td>-2.196400</td>\n",
       "      <td>-0.780610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.12340</td>\n",
       "      <td>1.18150</td>\n",
       "      <td>-0.555520</td>\n",
       "      <td>-0.811650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-2.31420</td>\n",
       "      <td>2.08380</td>\n",
       "      <td>-0.468130</td>\n",
       "      <td>-1.676700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.42330</td>\n",
       "      <td>-0.98912</td>\n",
       "      <td>2.358600</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-3.08660</td>\n",
       "      <td>-6.63620</td>\n",
       "      <td>10.540500</td>\n",
       "      <td>-0.891820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-4.73310</td>\n",
       "      <td>-6.17890</td>\n",
       "      <td>11.388000</td>\n",
       "      <td>-1.074100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variance  Skewness   Curtosis   Entropy  Class\n",
       "0     3.62160   8.66610  -2.807300 -0.446990      0\n",
       "1     4.54590   8.16740  -2.458600 -1.462100      0\n",
       "2     3.86600  -2.63830   1.924200  0.106450      0\n",
       "3     3.45660   9.52280  -4.011200 -3.594400      0\n",
       "4     0.32924  -4.45520   4.571800 -0.988800      0\n",
       "5     4.36840   9.67180  -3.960600 -3.162500      0\n",
       "6     3.59120   3.01290   0.728880  0.564210      0\n",
       "7     2.09220  -6.81000   8.463600 -0.602160      0\n",
       "8     3.20320   5.75880  -0.753450 -0.612510      0\n",
       "9     1.53560   9.17720  -2.271800 -0.735350      0\n",
       "10    1.22470   8.77790  -2.213500 -0.806470      0\n",
       "11    3.98990  -2.70660   2.394600  0.862910      0\n",
       "12    1.89930   7.66250   0.153940 -3.110800      0\n",
       "13   -1.57680  10.84300   2.546200 -2.936200      0\n",
       "14    3.40400   8.72610  -2.991500 -0.572420      0\n",
       "15    4.67650  -3.38950   3.489600  1.477100      0\n",
       "16    2.67190   3.06460   0.371580  0.586190      0\n",
       "17    0.80355   2.84730   4.343900  0.601700      0\n",
       "18    1.44790  -4.87940   8.342800 -2.108600      0\n",
       "19    5.24230  11.02720        NaN -4.101300      0\n",
       "20    5.78670   7.89020  -2.619600 -0.487080      0\n",
       "21    0.32920  -4.45520   4.571800 -0.988800      0\n",
       "22    3.93620  10.16220  -3.823500 -4.017200      0\n",
       "23    0.93584   8.88550  -1.683100 -1.659900      0\n",
       "24    4.43380   9.88700  -4.679500 -3.748300      0\n",
       "25    0.70570  -5.49810   8.336800 -2.871500      0\n",
       "26    1.14320  -3.74130   5.577700 -0.635780      0\n",
       "27   -0.38214   8.39090   2.162400 -3.740500      0\n",
       "28    6.56330   9.81870  -4.411300 -3.225800      0\n",
       "29    4.89060  -3.35840   3.420200  1.090500      0\n",
       "..        ...       ...        ...       ...    ...\n",
       "970  -2.32990  -9.95320   8.475600 -1.873300      1\n",
       "971   0.00312  -4.00610   1.795600  0.917220      1\n",
       "972   1.35180   1.05950  -2.343700  0.399980      1\n",
       "973   1.23090   3.89230  -4.827700 -4.006900      1\n",
       "974  -5.03010   7.50320  -0.133960 -7.503400      1\n",
       "975  -3.07990   0.60836   2.703900 -0.237510      1\n",
       "976  -2.29870  -5.22700   5.630000  0.917220      1\n",
       "977  -1.23900  -6.54100   4.815100 -0.033204      1\n",
       "978   0.75896   0.29176  -1.650600  0.838340      1\n",
       "979   1.67990   4.20680  -4.539800 -2.393100      1\n",
       "980   0.63655   5.20220  -5.215900 -6.121100      1\n",
       "981  -6.05980   9.29520  -0.436420 -6.369400      1\n",
       "982  -3.51800   2.87630   0.154800 -1.208600      1\n",
       "983  -2.03360  -1.40920   1.158200  0.365070      1\n",
       "984  -0.69745  -1.76720  -0.344740 -0.123720      1\n",
       "985   0.75108   1.91610  -3.109800 -0.205180      1\n",
       "986   0.84546   3.48260  -3.630700 -1.396100      1\n",
       "987  -0.55648   3.21360  -3.308500 -2.796500      1\n",
       "988  -3.68170   3.22390  -0.693470 -3.400400      1\n",
       "989  -6.75260   8.81720  -0.061983 -3.725000      1\n",
       "990  -4.57700   3.45150   0.667190 -0.947420      1\n",
       "991  -2.98830   0.31245   0.450410  0.068951      1\n",
       "992  -1.47810   0.14277  -1.162200 -0.485790      1\n",
       "993  -0.46651   2.33830  -2.981200 -1.043100      1\n",
       "994  -0.87340   1.65330  -2.196400 -0.780610      1\n",
       "995  -2.12340   1.18150  -0.555520 -0.811650      1\n",
       "996  -2.31420   2.08380  -0.468130 -1.676700      1\n",
       "997  -1.42330  -0.98912   2.358600  0.394810      1\n",
       "998  -3.08660  -6.63620  10.540500 -0.891820      1\n",
       "999  -4.73310  -6.17890  11.388000 -1.074100      1\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1000)  # we would like to perform a classification according to the variance, skewness, curtosis and entropy\n",
    "# we will determine if the banknote can be authenticated or not!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance    1\n",
      "Skewness    6\n",
      "Curtosis    8\n",
      "Entropy     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (dataset.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer  # Imputer is for missing values\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer()\n",
    "datasetClean = pd.DataFrame(my_imputer.fit_transform(dataset))\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "datasetClean.columns = dataset.columns\n",
    "# In general you can use this imputer without worrying about the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (datasetClean.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = datasetClean.corr()   # correlation calculation, we are trying to eliminate non-relevant columns from the dataset!\n",
    "cor_target = abs(cor[\"Class\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.0001]  # change the parameter, to see if you can get more \n",
    "#columns related to \"AveragePrice\" . In our case \"type\" columns looks not relevant therefore we are going to drop it!\n",
    "relevant_features.index\n",
    "# but what if we dont drop? we cannot guarantee that high correlation means good results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasetClean.drop('Entropy', axis=1, inplace=True)  #### according to the result of correlation we will drop this column. \n",
    "# What if it has still effect on the result despite of the correlation?\n",
    "#Examine the training with and without this \"type\" column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datasetClean.drop('Class', axis=1)\n",
    "y = datasetClean['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  # support vector machine - linear\n",
    "svclassifier = SVC(kernel='linear')\n",
    "fitted = svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148   4]\n",
      " [  0 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99       152\n",
      "         1.0       0.97      1.00      0.98       123\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.98      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 98.54545454545455 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('SVC:',accuracy_score(y_test, y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to predict the price, you can choose any row from data set and check if the prediction \"0\" or \"1\" is correct!\n",
    "test =datasetClean.loc[[1000]]   # take Nth row to check your prediction result manually \n",
    "test = test.drop('Class', axis=1)  # drop target \"class\" column\n",
    "prediction= fitted.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.364</td>\n",
       "      <td>2.1539</td>\n",
       "      <td>2.457</td>\n",
       "      <td>2.99532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy\n",
       "0     1.364    2.1539     2.457  2.99532"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now here is your new perspective, you cant always rely on numbers yea?\n",
    "# here is how you can really predict your ML algorithm. you show it a NEW data and it gives you a result!\n",
    "#dont forget about this part of code, you will need to check your final predictions in your career(dont worry about exam)\n",
    "\n",
    "data = [[1.364,2.1539,2.457,2.99532]]   # you can also create a dataframe by yourself and feed it into SVM prediction\n",
    "# imagine you have a banknote which has values as above. See if it can pass the authentication or not\n",
    "# 1 for the pass. 0 for not-pass\n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['Variance', 'Skewness','Curtosis','Entropy']) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction= fitted.predict(df)  # you can adjust the values and see what will your model generate.\n",
    "# this is a binary classification so result will be either 1 or 0 as yes or no.\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
